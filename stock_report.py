import pandas as pd
import yfinance as yf
from pykrx import stock
from datetime import datetime, timedelta
import os
import requests
from bs4 import BeautifulSoup
import time
import xml.etree.ElementTree as ET
import urllib.parse

def get_sector_data():
    """
    ê° ì„¹í„°ë³„ ìµœëŒ€ 10ê°œ ì¢…ëª© (ìœ ë™ì„± ë° ì‹œì´ ê³ ë ¤ ìƒìœ„ ì¢…ëª© ì¤‘ì‹¬)
    """
    return {
        "ë°˜ë„ì²´": ['005930.KS', '000660.KS', '042700.KS', '000990.KS', '058470.KQ', '222800.KQ', '067310.KQ', '176440.KQ', '036540.KQ', '032500.KQ'],
        "ì´ì°¨ì „ì§€": ['373220.KS', '006400.KS', '051910.KS', '247540.KQ', '091990.KQ', '066570.KS', '003670.KS', '391250.KQ', '078330.KQ', '086390.KQ'],
        "ìë™ì°¨/ë¶€í’ˆ": ['005380.KS', '000270.KS', '012330.KS', '011280.KS', '000660.KS', '002350.KS', '003620.KS', '010120.KS', '006110.KS', '009150.KS'],
        "ë°”ì´ì˜¤": ['207940.KS', '068270.KS', '000100.KS', '326030.KS', '183490.KQ', '066970.KS', '235980.KS', '096760.KS', '111770.KS', '006280.KS'],
        "ì¸í„°ë„·/í”Œë«í¼": ['035420.KS', '035720.KS', '323410.KS', '377300.KS', '112040.KQ', '060330.KQ', '193250.KQ', '067160.KQ', '253450.KQ', '353200.KS'],
        "ì€í–‰": ['105560.KS', '055550.KS', '024110.KS', '000030.KS', '138040.KS', '139130.KS', '316140.KS', '035720.KS', '323410.KS', '175330.KS'],
        "ì¦ê¶Œ/ì¹´ë“œ": ['005940.KS', '016360.KS', '039490.KS', '003550.KS', '008560.KS', '001270.KS', '029780.KS', '000810.KS', '030190.KS', '071050.KS'],
        "ë³´í—˜": ['005830.KS', '000810.KS', '032830.KS', '000400.KS', '002550.KS', '000060.KS', '014530.KS', '012140.KS', '012320.KS', '010140.KS'],
        "ì² ê°•/ê¸ˆì†": ['005490.KS', '004020.KS', '016380.KS', '001230.KS', '003030.KS', '010130.KS', '000670.KS', '001140.KS', '000140.KS', '000540.KS'],
        "ì •ìœ /í™”í•™": ['096770.KS', '010950.KS', '051910.KS', '011780.KS', '010130.KS', '004020.KS', '006120.KS', '003670.KS', '011170.KS', '010060.KS'],
        "ì¡°ì„ /ê¸°ê³„": ['042660.KS', '009540.KS', '010620.KS', '010120.KS', '003550.KS', '003620.KS', '001430.KS', '006280.KS', '000990.KS', '002350.KS'],
        "ë°©ì‚°": ['012450.KS', '047810.KS', '073190.KS', '000660.KS', '035720.KS', '005490.KS', '001230.KS', '004020.KS', '000100.KS', '005380.KS'],
        "ìš°ì£¼í•­ê³µ": ['047810.KS', '272210.KS', '440820.KS', '212560.KQ', '040910.KQ', '065350.KQ', '003620.KS', '006280.KS', '002350.KS', '010120.KS'],
        "ê±´ì„¤": ['000720.KS', '047040.KS', '006360.KS', '000810.KS', '002550.KS', '000060.KS', '014530.KS', '012140.KS', '012320.KS', '010140.KS'],
        "ë¡œë´‡": ['443250.KS', '043090.KQ', '189330.KQ', '389140.KQ', '214450.KQ', '137400.KQ', '222080.KS', '010120.KS', '000990.KS', '002350.KS'],
        "ì›ìë ¥": ['034020.KS', '052690.KS', '068290.KS', '000660.KS', '000990.KS', '002350.KS', '001430.KS', '006280.KS', '010120.KS', '003620.KS'],
        "í™”ì¥í’ˆ": ['051900.KS', '002790.KS', '192820.KS', '161890.KS', '214320.KS', '004020.KS', '001230.KS', '010130.KS', '000670.KS', '001140.KS'],
        "ê²Œì„": ['259960.KS', '036570.KS', '251270.KQ', '063080.KQ', '293490.KQ', '060330.KQ', '193250.KQ', '067160.KQ', '253450.KQ', '353200.KS'],
        "ì—”í„°í…Œì¸ë¨¼íŠ¸": ['352820.KS', '035900.KQ', '041510.KQ', '122870.KQ', '253450.KQ', '293490.KQ', '353200.KS', '060330.KQ', '193250.KQ', '067160.KQ'],
        "ì‹ìŒë£Œ": ['097950.KS', '004370.KS', '005180.KS', '000030.KS', '138040.KS', '139130.KS', '316140.KS', '035720.KS', '323410.KS', '175330.KS']
    }

def get_ticker_name(ticker):
    names = {
        '005930.KS': 'ì‚¼ì„±ì „ì', '000660.KS': 'SKí•˜ì´ë‹‰ìŠ¤', '373220.KS': 'LGì—”ì†”', '005380.KS': 'í˜„ëŒ€ì°¨',
        '000270.KS': 'ê¸°ì•„', '207940.KS': 'ì‚¼ì„±ë°”ì´ì˜¤', '068270.KS': 'ì…€íŠ¸ë¦¬ì˜¨', '035420.KS': 'NAVER',
        '035720.KS': 'ì¹´ì¹´ì˜¤', '105560.KS': 'KBê¸ˆìœµ', '055550.KS': 'ì‹ í•œì§€ì£¼', '005490.KS': 'POSCOí™€ë”©ìŠ¤',
        '017670.KS': 'SKí…”ë ˆì½¤', '030200.KS': 'KT', '259960.KS': 'í¬ë˜í”„í†¤', '352820.KS': 'í•˜ì´ë¸Œ',
        '051900.KS': 'LGìƒí™œê±´ê°•', '002790.KS': 'ì•„ëª¨ë ˆí¼ì‹œí”½', '096770.KS': 'SKì´ë…¸ë² ì´ì…˜',
        '010620.KS': 'í˜„ëŒ€ì¤‘ê³µì—…', '003490.KS': 'ëŒ€í•œí•­ê³µ', '011200.KS': 'HMM', '012450.KS': 'í•œí™”ì—ì–´ë¡œ',
        '000720.KS': 'í˜„ëŒ€ê±´ì„¤', '097950.KS': 'CJì œì¼ì œë‹¹', '023530.KS': 'ë¡¯ë°ì‡¼í•‘'
    }
    return names.get(ticker, ticker)

def get_naver_investor_data(ticker_code):
    code = ticker_code.split('.')[0]
    url = f"https://finance.naver.com/item/frgn.naver?code={code}"
    headers = {'User-Agent': 'Mozilla/5.0'}
    try:
        res = requests.get(url, headers=headers)
        content = res.content.decode('cp949', 'ignore')
        soup = BeautifulSoup(content, 'html.parser')
        tables = soup.find_all('table', class_='type2')
        target_table = None
        for t in tables:
            if 'ë‚ ì§œ' in t.text:
                target_table = t; break
        if not target_table: return None
        rows = target_table.find_all('tr')
        data = []
        for row in rows:
            cols = row.find_all('td')
            if len(cols) < 7: continue
            date_str = cols[0].text.strip().replace('.', '')
            if not date_str or len(date_str) != 8: continue
            try:
                volume = int(cols[4].text.replace(',', ''))
                inst_net = int(cols[5].text.replace(',', ''))
                for_net = int(cols[6].text.replace(',', ''))
                data.append({'ë‚ ì§œ': date_str, 'ê±°ë˜ëŸ‰': volume, 'ê¸°ê´€': inst_net, 'ì™¸êµ­ì¸': for_net, 'ê°œì¸': -(inst_net + for_net)})
            except: continue
        return pd.DataFrame(data)
    except: return None

def get_stats_yf_and_naver(tickers):
    data = yf.download(tickers, period="60d", interval="1d", progress=False)
    if data.empty: return None
    def get_ticker_df(t):
        if len(tickers) > 1:
            try: return data.xs(t, axis=1, level=1)
            except: return pd.DataFrame()
        return data
    naver_dfs = {}
    for t in tickers:
        df = get_naver_investor_data(t); naver_dfs[t] = df
        time.sleep(0.05)
    dates_yf = data.index.strftime("%Y%m%d").tolist()
    def calc_period_metrics(t_list, start_idx, end_idx, base_end_idx):
        prices, volumes = [], []
        ind_v_sum, for_v_sum, ins_v_sum = 0, 0, 0
        up_c, down_c, total_c = 0, 0, 0
        rep_ticker = t_list[0]
        rep_metrics = {"ê°€ê²©%": 0, "ê±°ë˜ëŸ‰": 0}
        start_date_str, end_date_str = dates_yf[start_idx], dates_yf[end_idx]
        for i, t in enumerate(t_list):
            tdf = get_ticker_df(t)
            if tdf.empty: continue
            try:
                curr_p, prev_p = tdf['Close'].iloc[end_idx], tdf['Close'].iloc[base_end_idx]
                p_change = (curr_p - prev_p) / prev_p * 100 if prev_p > 0 else 0
                if prev_p > 0:
                    prices.append(p_change); total_c += 1
                    if p_change > 0: up_c += 1
                    elif p_change < 0: down_c += 1
                v_sum = tdf['Volume'].iloc[start_idx:end_idx+1 if end_idx != -1 else None].sum()
                if not pd.isna(v_sum):
                    volumes.append(v_sum)
                    if i == 0: rep_metrics["ê±°ë˜ëŸ‰"] = int(v_sum)
                if i == 0: rep_metrics["ê°€ê²©%"] = round(p_change, 2)
                ndf = naver_dfs.get(t)
                if ndf is not None and not ndf.empty:
                    mask = (ndf['ë‚ ì§œ'] >= start_date_str) & (ndf['ë‚ ì§œ'] <= end_date_str)
                    period_ndf = ndf.loc[mask]
                    if not period_ndf.empty:
                        ind_v_sum += period_ndf['ê°œì¸'].sum(); for_v_sum += period_ndf['ì™¸êµ­ì¸'].sum(); ins_v_sum += period_ndf['ê¸°ê´€'].sum()
            except: continue
        avg_price = sum(prices) / len(prices) if prices else 0
        sum_vol = sum(volumes) if volumes else 0
        return {"ê°€ê²©%": round(avg_price, 2), "ê±°ë˜ëŸ‰": int(sum_vol), "ê°œì¸": int(ind_v_sum), "ì™¸ì¸": int(for_v_sum), "ê¸°ê´€": int(ins_v_sum), "ìƒìŠ¹/í•˜ë½": f"{up_c}/{down_c}", "ìƒìŠ¹ë¹„ìœ¨%": round((up_c/total_c*100),1) if total_c>0 else 0, "rep_name": get_ticker_name(rep_ticker), "rep_price%": rep_metrics["ê°€ê²©%"], "rep_vol": rep_metrics["ê±°ë˜ëŸ‰"]}
    res_t = calc_period_metrics(tickers, -1, -1, -2)
    res_y = calc_period_metrics(tickers, -2, -2, -3)
    res_w = calc_period_metrics(tickers, -5, -1, -6)
    return {"ë‹¹ì¼": res_t, "ì–´ì œ": res_y, "ì£¼ê°„": res_w}

def get_sector_news(sector, tickers):
    company_names = [get_ticker_name(t) for t in tickers[:3]]
    query = f"({sector}) OR ({' OR '.join(company_names)}) ì£¼ì‹ ë‰´ìŠ¤"
    encoded_query = urllib.parse.quote(query)
    url = f"https://news.google.com/rss/search?q={encoded_query}&hl=ko&gl=KR&ceid=KR:ko"
    headers = {'User-Agent': 'Mozilla/5.0'}
    today_dt = datetime.now()
    allowed_date = today_dt.strftime("%d %b %Y")
    try:
        res = requests.get(url, headers=headers, timeout=10)
        root = ET.fromstring(res.content)
        raw_news = []
        for item in root.findall('.//item'):
            if allowed_date not in item.find('pubDate').text: continue
            title = item.find('title').text
            link = item.find('link').text
            if ' - ' in title: title = title.rsplit(' - ', 1)[0]
            raw_news.append({'title': title, 'link': link})
            if len(raw_news) >= 30: break
        final_filtered, seen_norm = [], []
        for news in raw_news:
            curr_norm = "".join(news['title'].split()).lower()
            duplicate = False
            for seen in seen_norm:
                if curr_norm in seen or seen in curr_norm or (len(set(curr_norm).intersection(set(seen))) / max(len(curr_norm), len(seen)) > 0.6):
                    duplicate = True; break
            if not duplicate:
                final_filtered.append(f"- {news['title']} ([ë§í¬]({news['link']}))")
                seen_norm.append(curr_norm)
                if len(final_filtered) >= 3: break
        return final_filtered if final_filtered else ["- ê´€ë ¨ ë‰´ìŠ¤ê°€ ì—†ìŠµë‹ˆë‹¤."]
    except: return ["- ë‰´ìŠ¤ë¥¼ ë¶ˆëŸ¬ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤."]

def generate_summary(df, sector_news):
    summary = "## ğŸ“ ì‹œì¥ ë¶„ì„ ìš”ì•½\n\n"
    weekly_top = df.loc[df['ì£¼ê°„_ê°€ê²©%'].idxmax()]; weekly_worst = df.loc[df['ì£¼ê°„_ê°€ê²©%'].idxmin()]
    summary += f"### ğŸš€ ì£¼ê°„ ë² ìŠ¤íŠ¸ ì„¹í„°: **{weekly_top['ì„¹í„°']}**\n- ì§€ë‚œ ì¼ì£¼ì¼ê°„ í‰ê·  **{weekly_top['ì£¼ê°„_ê°€ê²©%']}%** ìƒìŠ¹ (ìƒìŠ¹ë¹„ìœ¨: **{weekly_top['ì£¼ê°„_ìƒìŠ¹ë¹„ìœ¨%']}%**)\n- ëŒ€í‘œ ì¢…ëª© **{weekly_top['rep_name']}**: ì£¼ê°„ **{weekly_top['ì£¼ê°„_rep_price%']}%** ë³€ë™, ê±°ë˜ëŸ‰ **{int(weekly_top['ì£¼ê°„_rep_vol']):,}ì£¼**\n\n"
    summary += f"### ğŸ“‰ ì£¼ê°„ ì›ŒìŠ¤íŠ¸ ì„¹í„°: **{weekly_worst['ì„¹í„°']}**\n- ì§€ë‚œ ì¼ì£¼ì¼ê°„ í‰ê·  **{weekly_worst['ì£¼ê°„_ê°€ê²©%']}%** í•˜ë½ (í•˜ë½ì¢…ëª©: **{weekly_worst['ì£¼ê°„_ìƒìŠ¹/í•˜ë½'].split('/')[1]}ê°œ**)\n- ëŒ€í‘œ ì¢…ëª© **{weekly_worst['rep_name']}**: ì£¼ê°„ **{weekly_worst['ì£¼ê°„_rep_price%']}%** ë³€ë™, ê±°ë˜ëŸ‰ **{int(weekly_worst['ì£¼ê°„_rep_vol']):,}ì£¼**\n\n"
    today_up = df[df['ë‹¹ì¼_ê°€ê²©%'] > 0]
    if not today_up.empty:
        top_today = today_up.loc[today_up['ë‹¹ì¼_ê°€ê²©%'].idxmax()]
        summary += f"### ğŸ“ˆ ë‹¹ì¼ ê°•ì„¸ ì„¹í„°: **{top_today['ì„¹í„°']}**\n- ì˜¤ëŠ˜ **{top_today['ë‹¹ì¼_ê°€ê²©%']}%** ìƒìŠ¹í•˜ë©° ì‹œì¥ ë°©ì–´. ëŒ€í‘œ ì¢…ëª© **{top_today['rep_name']}** (**{top_today['ë‹¹ì¼_rep_price%']}%**)\n\n"
    else:
        worst_today = df.loc[df['ë‹¹ì¼_ê°€ê²©%'].idxmin()]
        summary += f"### ğŸ“‰ ë‹¹ì¼ ì‹œì¥ ë™í–¥\n- ì˜¤ëŠ˜ ì‹œì¥ ì¡°ì •ì„¸. **{worst_today['ì„¹í„°']}** ì„¹í„° **{worst_today['ë‹¹ì¼_ê°€ê²©%']}%** í•˜ë½. (ëŒ€í‘œ ì¢…ëª© {worst_today['rep_name']} {worst_today['ë‹¹ì¼_rep_price%']}%)\n\n"
    summary += "### ğŸ“° ì£¼ìš” ì„¹í„° ë‰´ìŠ¤ ìš”ì•½\n"
    for sector in ["ë°˜ë„ì²´", "ì´ì°¨ì „ì§€", "ìë™ì°¨/ë¶€í’ˆ", "ë¡œë´‡", "AI/SW"]:
        if sector in sector_news:
            summary += f"**[{sector}]**\n" + "\n".join(sector_news[sector][:2]) + "\n\n"
    summary += "\n---"
    return summary

def main():
    print(f"í•œêµ­ ì¦ì‹œ ì„¹í„°ë³„ ì¢…í•© ë¦¬í¬íŠ¸ ({datetime.now().strftime('%Y-%m-%d %H:%M')})")
    sectors = get_sector_data(); results, sector_news_dict = [], {}
    for sector, tickers in sectors.items():
        print(f"ë¶„ì„ ì¤‘: {sector}...")
        metrics = get_stats_yf_and_naver(tickers)
        if not metrics: continue
        sector_news_dict[sector] = get_sector_news(sector, tickers)
        res = {"ì„¹í„°": sector, "ë‹¹ì¼_ê°€ê²©%": metrics["ë‹¹ì¼"]["ê°€ê²©%"], "ë‹¹ì¼_ê±°ë˜ëŸ‰": metrics["ë‹¹ì¼"]["ê±°ë˜ëŸ‰"], "ë‹¹ì¼_ì™¸ì¸": metrics["ë‹¹ì¼"]["ì™¸ì¸"], "ë‹¹ì¼_ê¸°ê´€": metrics["ë‹¹ì¼"]["ê¸°ê´€"], "ë‹¹ì¼_ê°œì¸": metrics["ë‹¹ì¼"]["ê°œì¸"], "ë‹¹ì¼_ìƒìŠ¹/í•˜ë½": metrics["ë‹¹ì¼"]["ìƒìŠ¹/í•˜ë½"], "ë‹¹ì¼_ìƒìŠ¹ë¹„ìœ¨%": metrics["ë‹¹ì¼"]["ìƒìŠ¹ë¹„ìœ¨%"], "ë‹¹ì¼_rep_price%": metrics["ë‹¹ì¼"]["rep_price%"], "ë‹¹ì¼_rep_vol": metrics["ë‹¹ì¼"]["rep_vol"], "ì–´ì œ_ê°€ê²©%": metrics["ì–´ì œ"]["ê°€ê²©%"], "ì–´ì œ_ê±°ë˜ëŸ‰": metrics["ì–´ì œ"]["ê±°ë˜ëŸ‰"], "ì–´ì œ_ì™¸ì¸": metrics["ì–´ì œ"]["ì™¸ì¸"], "ì–´ì œ_ê¸°ê´€": metrics["ì–´ì œ"]["ê¸°ê´€"], "ì–´ì œ_ê°œì¸": metrics["ì–´ì œ"]["ê°œì¸"], "ì–´ì œ_ìƒìŠ¹/í•˜ë½": metrics["ì–´ì œ"]["ìƒìŠ¹/í•˜ë½"], "ì–´ì œ_ìƒìŠ¹ë¹„ìœ¨%": metrics["ì–´ì œ"]["ìƒìŠ¹ë¹„ìœ¨%"], "ì–´ì œ_rep_price%": metrics["ì–´ì œ"]["rep_price%"], "ì–´ì œ_rep_vol": metrics["ì–´ì œ"]["rep_vol"], "ì£¼ê°„_ê°€ê²©%": metrics["ì£¼ê°„"]["ê°€ê²©%"], "ì£¼ê°„_ê±°ë˜ëŸ‰": metrics["ì£¼ê°„"]["ê±°ë˜ëŸ‰"], "ì£¼ê°„_ì™¸ì¸": metrics["ì£¼ê°„"]["ì™¸ì¸"], "ì£¼ê°„_ê¸°ê´€": metrics["ì£¼ê°„"]["ê¸°ê´€"], "ì£¼ê°„_ê°œì¸": metrics["ì£¼ê°„"]["ê°œì¸"], "ì£¼ê°„_ìƒìŠ¹/í•˜ë½": metrics["ì£¼ê°„"]["ìƒìŠ¹/í•˜ë½"], "ì£¼ê°„_ìƒìŠ¹ë¹„ìœ¨%": metrics["ì£¼ê°„"]["ìƒìŠ¹ë¹„ìœ¨%"], "ì£¼ê°„_rep_price%": metrics["ì£¼ê°„"]["rep_price%"], "ì£¼ê°„_rep_vol": metrics["ì£¼ê°„"]["rep_vol"], "rep_name": metrics["ë‹¹ì¼"]["rep_name"]}
        results.append(res)
    if not results: return
    df = pd.DataFrame(results).fillna(0)
    analysis_summary = generate_summary(df, sector_news_dict)
    today_str = datetime.now().strftime('%Y-%m-%d')
    filename = f"reports/report_{today_str}.md"
    os.makedirs("reports", exist_ok=True)
    with open(filename, "w", encoding="utf-8") as f:
        f.write(f"# í•œêµ­ ì¦ì‹œ ì„¹í„°ë³„ ì¢…í•© ë¦¬í¬íŠ¸ ({today_str})\n\n" + analysis_summary + "\n\n## ğŸ“Š ì„¹í„°ë³„ ì„¸ë¶€ ì§€í‘œ\n- ê°€ê²©% : ì„¹í„° ë‚´ ì¢…ëª©ë“¤ì˜ í‰ê·  ê°€ê²© ë³€ë™ë¥ \n- ê±°ë˜ëŸ‰ : í•´ë‹¹ ê¸°ê°„ ì„¹í„° ë‚´ ì¢…ëª©ë“¤ì˜ ì´ ê±°ë˜ëŸ‰ (ì£¼)\n- ì™¸ì¸/ê¸°ê´€/ê°œì¸ : í•´ë‹¹ ê¸°ê°„ ì„¹í„° ë‚´ ì¢…ëª©ë“¤ì˜ ìˆœë§¤ìˆ˜ ìˆ˜ëŸ‰ í•©ê³„ (ì£¼)\n- ìƒìŠ¹/í•˜ë½ : ì„¹í„° ë‚´ ìƒìŠ¹ ì¢…ëª© ìˆ˜ / í•˜ë½ ì¢…ëª© ìˆ˜\n- ìƒìŠ¹ë¹„ìœ¨% : ì„¹í„° ë‚´ ì „ì²´ ì¢…ëª© ì¤‘ ìƒìŠ¹í•œ ì¢…ëª©ì˜ ë¹„ì¤‘\n\n")
        for period in ["ë‹¹ì¼", "ì–´ì œ", "ì£¼ê°„"]:
            f.write(f"### {period} ë¦¬í¬íŠ¸\n\n")
            display_cols = ["ì„¹í„°", f"{period}_ê°€ê²©%", f"{period}_ìƒìŠ¹/í•˜ë½", f"{period}_ìƒìŠ¹ë¹„ìœ¨%", f"{period}_ê±°ë˜ëŸ‰", f"{period}_ì™¸ì¸", f"{period}_ê¸°ê´€", f"{period}_ê°œì¸"]
            sub_df = df[display_cols].copy(); sub_df.columns = [c.replace(f"{period}_", "") for c in sub_df.columns]
            sub_df = sub_df.sort_values(by=["ê°€ê²©%", "ê±°ë˜ëŸ‰"], ascending=False)
            for c in sub_df.columns:
                if sub_df[c].dtype in ['int64', 'float64'] and c not in ['ê°€ê²©%', 'ìƒìŠ¹ë¹„ìœ¨%']: sub_df[c] = sub_df[c].apply(lambda x: f"{int(x):,}")
            f.write(sub_df.to_markdown(index=False) + "\n\n")
        f.write("## ğŸ” ì„¹í„°ë³„ ì£¼ìš” ë‰´ìŠ¤ ì „ì²´ ë³´ê¸°\n\n")
        for sector, news in sector_news_dict.items():
            f.write(f"### {sector}\n" + "\n".join(news) + "\n\n")
        f.write("*ì´ ë¦¬í¬íŠ¸ëŠ” ìë™ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.*")
    print(f"\n[ì•Œë¦¼] ë§ˆí¬ë‹¤ìš´ ë¦¬í¬íŠ¸ê°€ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤: {filename}")

if __name__ == "__main__":
    main()
