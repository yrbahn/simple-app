import pandas as pd
import yfinance as yf
from pykrx import stock
from datetime import datetime, timedelta
import os
import requests
from bs4 import BeautifulSoup
import time
import xml.etree.ElementTree as ET
import urllib.parse

def get_sector_data():
    """
    ì•½ 30ê°œì˜ ì„¸ë¶„í™”ëœ ì„¹í„°ì™€ ì£¼ìš” ì¢…ëª© ë¦¬ìŠ¤íŠ¸
    """
    return {
        "ë°˜ë„ì²´": ['005930.KS', '000660.KS', '042700.KS', '000990.KS'],
        "ì´ì°¨ì „ì§€": ['373220.KS', '006400.KS', '051910.KS', '247540.KQ'],
        "ìë™ì°¨": ['005380.KS', '000270.KS', '012330.KS'],
        "ë°”ì´ì˜¤": ['207940.KS', '068270.KS', '326030.KS'],
        "ì¸í„°ë„·": ['035420.KS', '035720.KS'],
        "ì€í–‰": ['105560.KS', '055550.KS', '024110.KS'],
        "ì¦ê¶Œ": ['005940.KS', '016360.KS', '039490.KS'],
        "ë³´í—˜": ['005830.KS', '000810.KS', '032830.KS'],
        "ì² ê°•": ['005490.KS', '004020.KS'],
        "ì •ìœ /ì—ë„ˆì§€": ['096770.KS', '010950.KS'],
        "í™”í•™": ['051910.KS', '011780.KS', '010130.KS'],
        "ì¡°ì„ ": ['010620.KS', '042660.KS', '009540.KS'],
        "í•­ê³µ": ['003490.KS', '020560.KS', '272450.KS'],
        "í•´ìš´": ['011200.KS', '005880.KS'],
        "ë°©ì‚°": ['012450.KS', '047810.KS', '073190.KS'],
        "ìš°ì£¼í•­ê³µ": ['047810.KS', '272210.KS', '440820.KS'],
        "ê±´ì„¤": ['000720.KS', '047040.KS', '006360.KS'],
        "í†µì‹ ": ['017670.KS', '030200.KS', '032640.KS'],
        "ê²Œì„": ['259960.KS', '036570.KS', '251270.KQ'],
        "ì—”í„°í…Œì¸ë¨¼íŠ¸": ['352820.KS', '035900.KQ', '041510.KQ'],
        "í™”ì¥í’ˆ": ['051900.KS', '002790.KS', '192820.KS'],
        "ì‹ìŒë£Œ": ['097950.KS', '004370.KS', '005180.KS'],
        "ìœ í†µ/ë°±í™”ì ": ['023530.KS', '069960.KS', '004170.KS'],
        "ì˜ë£Œê¸°ê¸°": ['214450.KQ', '137400.KQ', '389140.KQ'],
        "ì „ë ¥ê¸°ê¸°": ['222080.KS', '010120.KS', '000990.KS'],
        "ë¡œë´‡": ['443250.KS', '043090.KQ', '189330.KQ'],
        "AI/SW": ['305270.KQ', '452100.KS', '307930.KQ'],
        "ì›ìë ¥": ['034020.KS', '052690.KS', '068290.KS'],
        "í•´ì™¸ì§êµ¬/ë¬¼ë¥˜": ['000120.KS', '011200.KS'],
        "ë¯¸ë””ì–´/ì›¹íˆ°": ['253450.KQ', '293490.KQ', '353200.KS']
    }

def get_ticker_name(ticker):
    names = {
        '005930.KS': 'ì‚¼ì„±ì „ì', '000660.KS': 'SKí•˜ì´ë‹‰ìŠ¤', '373220.KS': 'LGì—”ì†”', '005380.KS': 'í˜„ëŒ€ì°¨',
        '000270.KS': 'ê¸°ì•„', '207940.KS': 'ì‚¼ì„±ë°”ì´ì˜¤', '068270.KS': 'ì…€íŠ¸ë¦¬ì˜¨', '035420.KS': 'NAVER',
        '035720.KS': 'ì¹´ì¹´ì˜¤', '105560.KS': 'KBê¸ˆìœµ', '055550.KS': 'ì‹ í•œì§€ì£¼', '005490.KS': 'POSCOí™€ë”©ìŠ¤',
        '017670.KS': 'SKí…”ë ˆì½¤', '030200.KS': 'KT', '259960.KS': 'í¬ë˜í”„í†¤', '352820.KS': 'í•˜ì´ë¸Œ',
        '051900.KS': 'LGìƒí™œê±´ê°•', '002790.KS': 'ì•„ëª¨ë ˆí¼ì‹œí”½', '096770.KS': 'SKì´ë…¸ë² ì´ì…˜',
        '010620.KS': 'í˜„ëŒ€ì¤‘ê³µì—…', '003490.KS': 'ëŒ€í•œí•­ê³µ', '011200.KS': 'HMM', '012450.KS': 'í•œí™”ì—ì–´ë¡œ',
        '000720.KS': 'í˜„ëŒ€ê±´ì„¤', '097950.KS': 'CJì œì¼ì œë‹¹', '023530.KS': 'ë¡¯ë°ì‡¼í•‘'
    }
    return names.get(ticker, ticker)

def get_naver_investor_data(ticker_code):
    code = ticker_code.split('.')[0]
    url = f"https://finance.naver.com/item/frgn.naver?code={code}"
    headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'}
    try:
        res = requests.get(url, headers=headers)
        content = res.content.decode('cp949', 'ignore')
        soup = BeautifulSoup(content, 'html.parser')
        tables = soup.find_all('table', class_='type2')
        target_table = None
        for t in tables:
            if 'ë‚ ì§œ' in t.text:
                target_table = t
                break
        if not target_table: return None
        rows = target_table.find_all('tr')
        data = []
        for row in rows:
            cols = row.find_all('td')
            if len(cols) < 7: continue
            date_str = cols[0].text.strip().replace('.', '')
            if not date_str or len(date_str) != 8: continue
            try:
                volume = int(cols[4].text.replace(',', ''))
                inst_net = int(cols[5].text.replace(',', ''))
                for_net = int(cols[6].text.replace(',', ''))
                ind_net = -(inst_net + for_net)
                data.append({'ë‚ ì§œ': date_str, 'ê±°ë˜ëŸ‰': volume, 'ê¸°ê´€': inst_net, 'ì™¸êµ­ì¸': for_net, 'ê°œì¸': ind_net})
            except: continue
        return pd.DataFrame(data)
    except: return None

def get_stats_yf_and_naver(tickers):
    data = yf.download(tickers, period="60d", interval="1d", progress=False)
    if data.empty: return None
    def get_ticker_df(t):
        if len(tickers) > 1:
            try: return data.xs(t, axis=1, level=1)
            except: return pd.DataFrame()
        return data
    naver_dfs = {}
    for t in tickers:
        df = get_naver_investor_data(t)
        naver_dfs[t] = df
        time.sleep(0.1)
    dates_yf = data.index.strftime("%Y%m%d").tolist()
    def calc_period_metrics(t_list, start_idx, end_idx, base_end_idx):
        prices, volumes = [], []
        ind_v_sum, for_v_sum, ins_v_sum, total_v_sum = 0, 0, 0, 0
        start_date_str, end_date_str = dates_yf[start_idx], dates_yf[end_idx]
        for t in t_list:
            tdf = get_ticker_df(t)
            if tdf.empty: continue
            try:
                curr_p, prev_p = tdf['Close'].iloc[end_idx], tdf['Close'].iloc[base_end_idx]
                if prev_p > 0: prices.append((curr_p - prev_p) / prev_p * 100)
                v_sum = tdf['Volume'].iloc[start_idx:end_idx+1 if end_idx != -1 else None].sum()
                if not pd.isna(v_sum): volumes.append(v_sum)
                ndf = naver_dfs.get(t)
                if ndf is not None and not ndf.empty:
                    mask = (ndf['ë‚ ì§œ'] >= start_date_str) & (ndf['ë‚ ì§œ'] <= end_date_str)
                    period_ndf = ndf.loc[mask]
                    if not period_ndf.empty:
                        ind_v_sum += period_ndf['ê°œì¸'].sum()
                        for_v_sum += period_ndf['ì™¸êµ­ì¸'].sum()
                        ins_v_sum += period_ndf['ê¸°ê´€'].sum()
                        total_v_sum += period_ndf['ê±°ë˜ëŸ‰'].sum()
            except: continue
        avg_price = sum(prices) / len(prices) if prices else 0
        sum_vol = sum(volumes) if volumes else 0
        return {"ê°€ê²©%": round(avg_price, 2), "ê±°ë˜ëŸ‰": int(sum_vol), "ê°œì¸": int(ind_v_sum), "ì™¸ì¸": int(for_v_sum), "ê¸°ê´€": int(ins_v_sum)}
    res_t = calc_period_metrics(tickers, -1, -1, -2)
    res_y = calc_period_metrics(tickers, -2, -2, -3)
    res_w = calc_period_metrics(tickers, -5, -1, -6)
    return {"ë‹¹ì¼": res_t, "ì–´ì œ": res_y, "ì£¼ê°„": res_w}

def get_sector_news(sector, tickers):
    company_names = [get_ticker_name(t) for t in tickers[:2]]
    query = f"({sector}) OR ({' OR '.join(company_names)}) ì£¼ì‹ ë‰´ìŠ¤"
    encoded_query = urllib.parse.quote(query)
    url = f"https://news.google.com/rss/search?q={encoded_query}&hl=ko&gl=KR&ceid=KR:ko"
    headers = {'User-Agent': 'Mozilla/5.0'}
    today = datetime.now()
    yesterday = today - timedelta(days=1)
    allowed_dates = [today.strftime("%d %b %Y"), yesterday.strftime("%d %b %Y")]
    try:
        res = requests.get(url, headers=headers, timeout=10)
        root = ET.fromstring(res.content)
        raw_news = []
        for item in root.findall('.//item'):
            pub_date = item.find('pubDate').text
            is_recent = any(d in pub_date for d in allowed_dates)
            title = item.find('title').text
            link = item.find('link').text
            if ' - ' in title: title = title.rsplit(' - ', 1)[0]
            raw_news.append({'title': title, 'link': link, 'recent': is_recent})
            if len(raw_news) >= 20: break
        raw_news.sort(key=lambda x: x['recent'], reverse=True)
        filtered_news, seen_titles = [], []
        for news in raw_news:
            is_duplicate = False
            current_words = set(news['title'].split())
            for prev_title in seen_titles:
                prev_words = set(prev_title.split())
                intersection = current_words.intersection(prev_words)
                if len(intersection) / max(1, min(len(current_words), len(prev_words))) > 0.5:
                    is_duplicate = True
                    break
            if not is_duplicate:
                prefix = "ğŸ”¥ " if news['recent'] else "ğŸ•’ "
                filtered_news.append(f"{prefix}{news['title']} ([ë§í¬]({news['link']}))")
                seen_titles.append(news['title'])
                if len(filtered_news) >= 3: break
        return filtered_news if filtered_news else ["- ê´€ë ¨ ë‰´ìŠ¤ê°€ ì—†ìŠµë‹ˆë‹¤."]
    except: return ["- ë‰´ìŠ¤ë¥¼ ë¶ˆëŸ¬ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤."]

def generate_summary(df, sector_news):
    summary = "## ğŸ“ ì‹œì¥ ë¶„ì„ ìš”ì•½\n\n"
    weekly_top = df.loc[df['ì£¼ê°„_ê°€ê²©%'].idxmax()]
    summary += f"### ğŸš€ ì£¼ê°„ ë² ìŠ¤íŠ¸ ì„¹í„°: **{weekly_top['ì„¹í„°']}**\n- ì§€ë‚œ ì¼ì£¼ì¼ê°„ í‰ê·  **{weekly_top['ì£¼ê°„_ê°€ê²©%']}%** ìƒìŠ¹í•˜ë©° ê°€ì¥ ê°•í•œ íë¦„ì„ ë³´ì˜€ìŠµë‹ˆë‹¤.\n\n"
    today_up = df[df['ë‹¹ì¼_ê°€ê²©%'] > 0]
    if not today_up.empty:
        top_today = today_up.loc[today_up['ë‹¹ì¼_ê°€ê²©%'].idxmax()]
        summary += f"### ğŸ“ˆ ë‹¹ì¼ ê°•ì„¸ ì„¹í„°: **{top_today['ì„¹í„°']}**\n- ì˜¤ëŠ˜ ì‹œì¥ì—ì„œ **{top_today['ë‹¹ì¼_ê°€ê²©%']}%** ìƒìŠ¹í•˜ë©° ì£¼ëª©ë°›ì•˜ìŠµë‹ˆë‹¤.\n\n"
    else:
        worst_today = df.loc[df['ë‹¹ì¼_ê°€ê²©%'].idxmin()]
        summary += f"### ğŸ“‰ ë‹¹ì¼ ì‹œì¥ ë™í–¥\n- ì „ë°˜ì ìœ¼ë¡œ ì•½ì„¸ì¥ì´ì—ˆìœ¼ë©°, **{worst_today['ì„¹í„°']}** ì„¹í„°ì˜ í•˜ë½í­ì´ ì»¸ìŠµë‹ˆë‹¤.\n\n"
    summary += "### ğŸ“° ì£¼ìš” ì„¹í„° ë‰´ìŠ¤ ìš”ì•½\n"
    for sector in ["ë°˜ë„ì²´", "ì´ì°¨ì „ì§€", "ìë™ì°¨", "ë¡œë´‡", "AI/SW"]:
        if sector in sector_news:
            summary += f"**[{sector}]**\n" + "\n".join(sector_news[sector][:2]) + "\n\n"
    summary += "\n---"
    return summary

def main():
    print("=" * 80)
    print(f"í•œêµ­ ì¦ì‹œ ì„¹í„°ë³„ ì¢…í•© ë¦¬í¬íŠ¸ ({datetime.now().strftime('%Y-%m-%d %H:%M')})")
    print("=" * 80)
    sectors = get_sector_data()
    results, sector_news_dict = [], {}
    for sector, tickers in sectors.items():
        print(f"ë¶„ì„ ì¤‘: {sector}...")
        metrics = get_stats_yf_and_naver(tickers)
        if not metrics: continue
        print(f"  - {sector} ë‰´ìŠ¤ ê²€ìƒ‰ ì¤‘...")
        sector_news_dict[sector] = get_sector_news(sector, tickers)
        res = {"ì„¹í„°": sector, "ë‹¹ì¼_ê°€ê²©%": metrics["ë‹¹ì¼"]["ê°€ê²©%"], "ë‹¹ì¼_ê±°ë˜ëŸ‰": metrics["ë‹¹ì¼"]["ê±°ë˜ëŸ‰"], "ë‹¹ì¼_ì™¸ì¸": metrics["ë‹¹ì¼"]["ì™¸ì¸"], "ë‹¹ì¼_ê¸°ê´€": metrics["ë‹¹ì¼"]["ê¸°ê´€"], "ë‹¹ì¼_ê°œì¸": metrics["ë‹¹ì¼"]["ê°œì¸"], "ì–´ì œ_ê°€ê²©%": metrics["ì–´ì œ"]["ê°€ê²©%"], "ì–´ì œ_ê±°ë˜ëŸ‰": metrics["ì–´ì œ"]["ê±°ë˜ëŸ‰"], "ì–´ì œ_ì™¸ì¸": metrics["ì–´ì œ"]["ì™¸ì¸"], "ì–´ì œ_ê¸°ê´€": metrics["ì–´ì œ"]["ê¸°ê´€"], "ì–´ì œ_ê°œì¸": metrics["ì–´ì œ"]["ê°œì¸"], "ì£¼ê°„_ê°€ê²©%": metrics["ì£¼ê°„"]["ê°€ê²©%"], "ì£¼ê°„_ê±°ë˜ëŸ‰": metrics["ì£¼ê°„"]["ê±°ë˜ëŸ‰"], "ì£¼ê°„_ì™¸ì¸": metrics["ì£¼ê°„"]["ì™¸ì¸"], "ì£¼ê°„_ê¸°ê´€": metrics["ì£¼ê°„"]["ê¸°ê´€"], "ì£¼ê°„_ê°œì¸": metrics["ì£¼ê°„"]["ê°œì¸"]}
        results.append(res)
    if results: df = pd.DataFrame(results).fillna(0)
    else: return
    analysis_summary = generate_summary(df, sector_news_dict)
    today_str = datetime.now().strftime('%Y-%m-%d')
    filename = f"reports/report_{today_str}.md"
    os.makedirs("reports", exist_ok=True)
    with open(filename, "w", encoding="utf-8") as f:
        f.write(f"# í•œêµ­ ì¦ì‹œ ì„¹í„°ë³„ ì¢…í•© ë¦¬í¬íŠ¸ ({today_str})\n\n" + analysis_summary + "\n\n## ğŸ“Š ì„¹í„°ë³„ ì„¸ë¶€ ì§€í‘œ\n- ê°€ê²©% : ì„¹í„° ë‚´ ì¢…ëª©ë“¤ì˜ í‰ê·  ê°€ê²© ë³€ë™ë¥ \n- ê±°ë˜ëŸ‰ : í•´ë‹¹ ê¸°ê°„ ì„¹í„° ë‚´ ì¢…ëª©ë“¤ì˜ ì´ ê±°ë˜ëŸ‰ (ì£¼)\n- ì™¸ì¸/ê¸°ê´€/ê°œì¸ : í•´ë‹¹ ê¸°ê°„ ì„¹í„° ë‚´ ì¢…ëª©ë“¤ì˜ ìˆœë§¤ìˆ˜ ìˆ˜ëŸ‰ í•©ê³„ (ì£¼)\n\n")
        for period in ["ë‹¹ì¼", "ì–´ì œ", "ì£¼ê°„"]:
            f.write(f"### {period} ë¦¬í¬íŠ¸\n\n")
            cols = ["ì„¹í„°"] + [c for c in df.columns if c.startswith(period)]
            sub_df = df[cols].copy()
            sub_df.columns = [c.replace(f"{period}_", "") for c in sub_df.columns]
            for c in sub_df.columns:
                if sub_df[c].dtype in ['int64', 'float64'] and c != 'ê°€ê²©%':
                    sub_df[c] = sub_df[c].apply(lambda x: f"{int(x):,}")
            f.write(sub_df.to_markdown(index=False) + "\n\n")
        f.write("## ğŸ” ì„¹í„°ë³„ ì£¼ìš” ë‰´ìŠ¤ ì „ì²´ ë³´ê¸°\n\n")
        for sector, news in sector_news_dict.items():
            f.write(f"### {sector}\n" + "\n".join(news) + "\n\n")
        f.write("*ì´ ë¦¬í¬íŠ¸ëŠ” ìë™ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.*")
    print(f"\n[ì•Œë¦¼] ë§ˆí¬ë‹¤ìš´ ë¦¬í¬íŠ¸ê°€ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤: {filename}")

if __name__ == "__main__":
    main()
